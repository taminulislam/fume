{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUME-FastSCNN Training Notebook\n",
    "\n",
    "This notebook trains the FUME-FastSCNN model for dual-gas acidosis detection.\n",
    "\n",
    "**Model:** FUME-FastSCNN (~2.8M parameters)\n",
    "**Task:** Multi-task (Segmentation + Classification)\n",
    "**Dataset:** Augmented gas emission dataset (8,967 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA RTX 6000 Ada Generation\n",
      "CUDA version: 12.8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Check CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration loaded:\n",
      "  Experiment: FUME-FastSCNN\n",
      "  Model: FUMEFastSCNN\n",
      "  Batch size: 8\n",
      "  Epochs: 50\n",
      "  Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Load config\n",
    "config_path = '../configs/fume_fastscnn_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "print(f\"  Experiment: {config['experiment']['name']}\")\n",
    "print(f\"  Model: {config['model']['name']}\")\n",
    "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"  Learning rate: {config['training']['optimizer']['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "**First, run the data pairing script if not already done:**\n",
    "\n",
    "```bash\n",
    "cd ../data\n",
    "python pairing.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All paired annotation files found!\n"
     ]
    }
   ],
   "source": [
    "# Check if paired annotations exist\n",
    "import os\n",
    "\n",
    "required_files = [\n",
    "    '../data/paired_train_annotations.csv',\n",
    "    '../data/paired_val_annotations.csv',\n",
    "    '../data/paired_test_annotations.csv'\n",
    "]\n",
    "\n",
    "all_exist = all(os.path.exists(f) for f in required_files)\n",
    "\n",
    "if all_exist:\n",
    "    print(\"‚úÖ All paired annotation files found!\")\n",
    "else:\n",
    "    print(\"‚ùå Paired annotation files not found. Run data/pairing.py first!\")\n",
    "    print(\"\\nRun this command in terminal:\")\n",
    "    print(\"  cd data && python pairing.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Statistics:\n",
      "  Total parameters: 1,656,236\n",
      "  Parameters (M): 1.66M\n",
      "  Within budget: Yes\n",
      "\n",
      "Output shapes:\n",
      "  Classification: torch.Size([1, 3])\n",
      "  CO2 Segmentation: torch.Size([1, 3, 480, 640])\n",
      "  CH4 Segmentation: torch.Size([1, 3, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "from models import FUMEFastSCNN\n",
    "\n",
    "# Create model\n",
    "model = FUMEFastSCNN(\n",
    "    num_classes=3,\n",
    "    num_seg_classes=3,\n",
    "    shared_encoder=True\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "num_params = model.get_num_parameters()\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Total parameters: {num_params:,}\")\n",
    "print(f\"  Parameters (M): {num_params/1e6:.2f}M\")\n",
    "print(f\"  Within budget: {'Yes' if num_params < 3e6 else 'No'}\")\n",
    "\n",
    "# Test forward pass (use eval mode for inference testing)\n",
    "model.eval()\n",
    "dummy_co2 = torch.randn(1, 1, 480, 640)\n",
    "dummy_ch4 = torch.randn(1, 1, 480, 640)\n",
    "dummy_mask = torch.ones(1, 2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(dummy_co2, dummy_ch4, dummy_mask)\n",
    "print(f\"\\nOutput shapes:\")\n",
    "print(f\"  Classification: {outputs['cls_logits'].shape}\")\n",
    "print(f\"  CO2 Segmentation: {outputs['co2_seg_logits'].shape}\")\n",
    "print(f\"  CH4 Segmentation: {outputs['ch4_seg_logits'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B: Train in notebook (for debugging)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/siu856569517/Taminul/Acidosis/FUME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siu856569517/.conda/envs/fume_env/lib/python3.9/site-packages/wandb/sdk/launch/builder/build.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Seed set to 42\n",
      "üöÄ Using device: cuda\n",
      "‚úÖ Directories created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siu856569517/.conda/envs/fume_env/lib/python3.9/site-packages/wandb/sdk/launch/builder/build.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaminul\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/siu856569517/Taminul/Acidosis/FUME/wandb/run-20251201_034204-hs7o9al3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/taminul/FUME-Acidosis/runs/hs7o9al3' target=\"_blank\">FUME-FastSCNN</a></strong> to <a href='https://wandb.ai/taminul/FUME-Acidosis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/taminul/FUME-Acidosis' target=\"_blank\">https://wandb.ai/taminul/FUME-Acidosis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/taminul/FUME-Acidosis/runs/hs7o9al3' target=\"_blank\">https://wandb.ai/taminul/FUME-Acidosis/runs/hs7o9al3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.dataset:Loaded 4383 paired samples\n",
      "INFO:data.dataset:  Fully paired: 1893\n",
      "INFO:data.dataset:  Modality dropout: 0.2\n",
      "INFO:data.dataset:  Class distribution: {'Acidotic': 2734, 'Healthy': 1488, 'Transitional': 161}\n",
      "INFO:data.dataset:Loaded 939 paired samples\n",
      "INFO:data.dataset:  Fully paired: 406\n",
      "INFO:data.dataset:  Modality dropout: 0.0\n",
      "INFO:data.dataset:  Class distribution: {'Acidotic': 586, 'Healthy': 318, 'Transitional': 35}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ W&B initialized: FUME-Acidosis/FUME-FastSCNN\n",
      "   Run ID: hs7o9al3\n",
      "   View at: https://wandb.ai/taminul/FUME-Acidosis/runs/hs7o9al3\n",
      "‚úÖ Logger initialized\n",
      "‚úÖ Data loaded: 4383 train, 939 val samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siu856569517/Taminul/Acidosis/FUME/train.py:238: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler() if self.config['training']['use_amp'] else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created: 1,656,236 parameters (1.66M)\n",
      "‚úÖ Model logged: model (1.66M params)\n",
      "‚úÖ Loss function initialized\n",
      "‚úÖ Optimizer and scheduler initialized\n",
      "‚úÖ Metrics initialized\n",
      "\n",
      "======================================================================\n",
      "üöÄ Starting Training\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/548 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train.py:268: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
      "Epoch 1/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548/548 [05:09<00:00,  1.77it/s, loss=0.284]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [00:12<00:00, 77.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 5.36 minutes\n",
      "Best metric: 0.3339\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   0%|          | 0/548 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train.py:268: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
      "Epoch 2/50:   2%|‚ñè         | 10/548 [00:08<05:51,  1.53it/s, loss=1.19] \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 1 is less than current step: 1048. Dropping entry: {'val_loss': 8.448084470436088, 'val_pixel_accuracy': 0.8793279953463348, 'val_mean_iou': 0.6122940599115602, 'val_mean_dice': 0.7453894045240793, 'val_iou_background': 0.8629832408256963, 'val_iou_tube': 0.4737004678684074, 'val_iou_gas': 0.5001984710405769, 'val_dice_background': 0.9264530371655001, 'val_dice_tube': 0.6428721143769169, 'val_dice_gas': 0.6668430620298208, 'val_accuracy': 0.3397231096911608, 'val_balanced_accuracy': 0.3339021615472127, 'val_macro_f1': 0.16992552725904866, 'val_weighted_f1': 0.17361242870285498, 'val_cohens_kappa': 0.0011512376233375754, 'val_Healthy_precision': 0.3390191897654584, 'val_Healthy_recall': 1.0, 'val_Healthy_f1': 0.5063694267515924, 'val_Transitional_precision': 0.0, 'val_Transitional_recall': 0.0, 'val_Transitional_f1': 0.0, 'val_Acidotic_precision': 1.0, 'val_Acidotic_recall': 0.0017064846416382253, 'val_Acidotic_f1': 0.003407155025553663, 'step': 1, '_timestamp': 1764582449.1237154}).\n",
      "Epoch 2/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548/548 [05:03<00:00,  1.81it/s, loss=0.291]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [00:12<00:00, 73.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed in 5.27 minutes\n",
      "Best metric: 0.3799\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:   0%|          | 0/548 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train.py:268: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
      "Epoch 3/50:   2%|‚ñè         | 9/548 [00:06<06:17,  1.43it/s, loss=0.61] \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 2 is less than current step: 1596. Dropping entry: {'val_loss': 17.492131134080555, 'val_pixel_accuracy': 0.8657040367356674, 'val_mean_iou': 0.6418505019473696, 'val_mean_dice': 0.7733563486935163, 'val_iou_background': 0.8409348150351615, 'val_iou_tube': 0.5455234777771524, 'val_iou_gas': 0.5390932130297946, 'val_dice_background': 0.9135954278957996, 'val_dice_tube': 0.7059400722423848, 'val_dice_gas': 0.7005335459423646, 'val_accuracy': 0.44195953141640043, 'val_balanced_accuracy': 0.3798806534011634, 'val_macro_f1': 0.2845655211782544, 'val_weighted_f1': 0.38041074335541075, 'val_cohens_kappa': 0.10126307137312196, 'val_Healthy_precision': 0.37220843672456577, 'val_Healthy_recall': 0.9433962264150944, 'val_Healthy_f1': 0.5338078291814947, 'val_Transitional_precision': 0.0, 'val_Transitional_recall': 0.0, 'val_Transitional_f1': 0.0, 'val_Acidotic_precision': 0.8646616541353384, 'val_Acidotic_recall': 0.1962457337883959, 'val_Acidotic_f1': 0.3198887343532685, 'step': 2, '_timestamp': 1764582765.2383163}).\n",
      "Epoch 3/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548/548 [05:07<00:00,  1.78it/s, loss=0.224]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [00:12<00:00, 76.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed in 5.33 minutes\n",
      "Best metric: 0.3970\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50:   0%|          | 0/548 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 3 is less than current step: 2144. Dropping entry: {'val_loss': 11.744354741864058, 'val_pixel_accuracy': 0.910315772541711, 'val_mean_iou': 0.7192431952749185, 'val_mean_dice': 0.8308861096623593, 'val_iou_background': 0.8947582063548074, 'val_iou_tube': 0.6384734227656287, 'val_iou_gas': 0.6244979567043195, 'val_dice_background': 0.9444563463072896, 'val_dice_tube': 0.7793515767719078, 'val_dice_gas': 0.7688504059078808, 'val_accuracy': 0.4579339723109691, 'val_balanced_accuracy': 0.3970420932878271, 'val_macro_f1': 0.2921251402426563, 'val_weighted_f1': 0.3883845734297337, 'val_cohens_kappa': 0.13587342683008385, 'val_Healthy_precision': 0.3845223700120919, 'val_Healthy_recall': 1.0, 'val_Healthy_f1': 0.5554585152838428, 'val_Transitional_precision': 0.0, 'val_Transitional_recall': 0.0, 'val_Transitional_f1': 0.0, 'val_Acidotic_precision': 1.0, 'val_Acidotic_recall': 0.19112627986348124, 'val_Acidotic_f1': 0.3209169054441261, 'step': 3, '_timestamp': 1764583085.0903428}).\n",
      "/home/siu856569517/Taminul/Acidosis/FUME/train.py:268: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
      "Epoch 4/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548/548 [04:58<00:00,  1.84it/s, loss=0.241]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [00:12<00:00, 76.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed in 5.18 minutes\n",
      "Best metric: 0.4016\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:   0%|          | 0/548 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train.py:268: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
      "Epoch 5/50:   2%|‚ñè         | 12/548 [00:05<03:10,  2.82it/s, loss=9.04]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 4 is less than current step: 2692. Dropping entry: {'val_loss': 17.26724694884274, 'val_pixel_accuracy': 0.915406505840655, 'val_mean_iou': 0.7001679182532642, 'val_mean_dice': 0.8153412771037994, 'val_iou_background': 0.9006227030434751, 'val_iou_tube': 0.5595224109051972, 'val_iou_gas': 0.6403586408111205, 'val_dice_background': 0.9477132958596193, 'val_dice_tube': 0.7175561017817401, 'val_dice_gas': 0.7807544336700388, 'val_accuracy': 0.46645367412140576, 'val_balanced_accuracy': 0.40159271899886234, 'val_macro_f1': 0.2997700324645394, 'val_weighted_f1': 0.4015819242121334, 'val_cohens_kappa': 0.14614517595683163, 'val_Healthy_precision': 0.3882783882783883, 'val_Healthy_recall': 1.0, 'val_Healthy_f1': 0.5593667546174143, 'val_Transitional_precision': 0.0, 'val_Transitional_recall': 0.0, 'val_Transitional_f1': 0.0, 'val_Acidotic_precision': 1.0, 'val_Acidotic_recall': 0.20477815699658702, 'val_Acidotic_f1': 0.33994334277620397, 'step': 4, '_timestamp': 1764583395.7313235}).\n",
      "Epoch 5/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548/548 [04:59<00:00,  1.83it/s, loss=0.29] \n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [00:12<00:00, 76.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  EPOCH 5 RESULTS\n",
      "======================================================================\n",
      "\n",
      "  LOSS\n",
      "----------------------------------------\n",
      "  Train Loss                0.4830\n",
      "  Val Loss                  12.5227\n",
      "\n",
      "  SEGMENTATION METRICS\n",
      "----------------------------------------\n",
      "  mean_iou                  0.7352\n",
      "  mean_dice                 0.8421\n",
      "  pixel_accuracy            0.9180\n",
      "\n",
      "  CLASSIFICATION METRICS\n",
      "----------------------------------------\n",
      "  accuracy                  0.4633\n",
      "  balanced_accuracy         0.3984\n",
      "  macro_f1                  0.2980\n",
      "  weighted_f1               0.3994\n",
      "  cohens_kappa              0.1398\n",
      "\n",
      "  PER-CLASS F1 SCORES\n",
      "----------------------------------------\n",
      "  Healthy                   0.5556\n",
      "  Transitional              0.0000\n",
      "  Acidotic                  0.3385\n",
      "======================================================================\n",
      "\n",
      "Epoch 5 completed in 5.20 minutes\n",
      "Best metric: 0.4016\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:   0%|          | 0/548 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train.py:268: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
      "Epoch 6/50:   2%|‚ñè         | 10/548 [00:07<06:57,  1.29it/s, loss=0.162]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 5 is less than current step: 3240. Dropping entry: {'val_loss': 12.52269748551523, 'val_pixel_accuracy': 0.9180346445686901, 'val_mean_iou': 0.7351839921012431, 'val_mean_dice': 0.8421294885220388, 'val_iou_background': 0.9040686621765441, 'val_iou_tube': 0.6599863975039725, 'val_iou_gas': 0.6414969166232125, 'val_dice_background': 0.9496177108897971, 'val_dice_tube': 0.7951708501905277, 'val_dice_gas': 0.781599904485792, 'val_accuracy': 0.46325878594249204, 'val_balanced_accuracy': 0.398448064910812, 'val_macro_f1': 0.2980201640286267, 'val_weighted_f1': 0.39939356706436296, 'val_cohens_kappa': 0.1397769719442703, 'val_Healthy_precision': 0.3860294117647059, 'val_Healthy_recall': 0.9905660377358491, 'val_Healthy_f1': 0.5555555555555556, 'val_Transitional_precision': 0.0, 'val_Transitional_recall': 0.0, 'val_Transitional_f1': 0.0, 'val_Acidotic_precision': 0.975609756097561, 'val_Acidotic_recall': 0.20477815699658702, 'val_Acidotic_f1': 0.33850493653032443, 'step': 5, '_timestamp': 1764583707.8936422}).\n",
      "Epoch 6/50:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 451/548 [04:16<00:42,  2.28it/s, loss=0.351]"
     ]
    }
   ],
   "source": [
    "# Import trainer\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "# Change to project root (required for config relative paths)\n",
    "os.chdir('..')\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(config_path='configs/fume_fastscnn_config.yaml')\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitor Training\n",
    "\n",
    "**Weights & Biases Dashboard:**\n",
    "- View training curves in real-time\n",
    "- Compare experiments\n",
    "- Track system metrics\n",
    "\n",
    "**TensorBoard (if W&B not available):**\n",
    "```bash\n",
    "tensorboard --logdir=logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load and Test Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "checkpoint_path = '../checkpoints/best_model.pth'\n",
    "\n",
    "if Path(checkpoint_path).exists():\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    # Load model\n",
    "    model = FUMEFastSCNN(\n",
    "        num_classes=3,\n",
    "        num_seg_classes=3,\n",
    "        shared_encoder=True\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"‚úÖ Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"   Best metric: {checkpoint['best_metric']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint found. Train the model first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Summary\n",
    "\n",
    "After training completes, check:\n",
    "- `checkpoints/best_model.pth` - Best model weights\n",
    "- `checkpoints/last_model.pth` - Latest model weights\n",
    "- `logs/` - Training logs\n",
    "- W&B dashboard - Training curves and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. ‚úÖ Training completed\n",
    "2. üìä Evaluate on test set (use `test_fume.ipynb`)\n",
    "3. üìà Compare with baselines\n",
    "4. üî¨ Run ablation studies\n",
    "5. üìù Generate paper figures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fume_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
