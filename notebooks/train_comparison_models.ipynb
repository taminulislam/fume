{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparison Models Training Notebook\n",
        "\n",
        "This notebook trains all 8 comparison models for benchmarking against FUME-FastSCNN.\n",
        "\n",
        "**Models:** BiSeNetV2, CMX, DDRNetSlim, RTFNet, ESPNetV2, MTINet, ENet, DANet\n",
        "\n",
        "**Fast Training Configuration:**\n",
        "- 15 epochs (instead of 50)\n",
        "- Batch size: 16 (increased from 8)\n",
        "- Learning rate: 0.002 (2x higher for fast convergence)\n",
        "- 8 workers for faster data loading\n",
        "- Minimal augmentation\n",
        "- Mixed precision (AMP) enabled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0+cu128\n",
            "CUDA available: True\n",
            "CUDA device: NVIDIA RTX 6000 Ada Generation\n",
            "CUDA version: 12.8\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fast Training Configuration:\n",
            "  Epochs: 15\n",
            "  Batch size: 16\n",
            "  Learning rate: 0.002\n",
            "  Num workers: 8\n",
            "  Mixed precision: True\n",
            "  W&B enabled: True\n"
          ]
        }
      ],
      "source": [
        "config_path = '../configs/fast_comparison_config.yaml'\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Fast Training Configuration:\")\n",
        "print(f\"  Epochs: {config['training']['num_epochs']}\")\n",
        "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
        "print(f\"  Learning rate: {config['training']['optimizer']['lr']}\")\n",
        "print(f\"  Num workers: {config['training']['num_workers']}\")\n",
        "print(f\"  Mixed precision: {config['training']['use_amp']}\")\n",
        "print(f\"  W&B enabled: {config['experiment']['use_wandb']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Comparison Models Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models to train:\n",
            "======================================================================\n",
            "1. BiSeNetV2       | 3.4M     | Bilateral dual-path\n",
            "2. CMX             | 3.8M     | Cross-modal transformer\n",
            "3. DDRNetSlim      | 5.7M     | Dual-resolution network\n",
            "4. RTFNet          | 4.2M     | RGB-Thermal fusion\n",
            "5. ESPNetV2        | 1.2M     | Spatial pyramid\n",
            "6. MTINet          | 3.5M     | Multi-task interaction\n",
            "7. ENet            | 0.4M     | Ultra-lightweight\n",
            "8. DANet           | 3.2M     | Dual attention\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "from models import (\n",
        "    BiSeNetV2,\n",
        "    CMX,\n",
        "    DDRNetSlim,\n",
        "    RTFNet,\n",
        "    ESPNetV2,\n",
        "    MTINet,\n",
        "    ENet,\n",
        "    DANet\n",
        ")\n",
        "\n",
        "models_info = [\n",
        "    {'name': 'BiSeNetV2', 'params': '3.4M', 'type': 'Bilateral dual-path'},\n",
        "    {'name': 'CMX', 'params': '3.8M', 'type': 'Cross-modal transformer'},\n",
        "    {'name': 'DDRNetSlim', 'params': '5.7M', 'type': 'Dual-resolution network'},\n",
        "    {'name': 'RTFNet', 'params': '4.2M', 'type': 'RGB-Thermal fusion'},\n",
        "    {'name': 'ESPNetV2', 'params': '1.2M', 'type': 'Spatial pyramid'},\n",
        "    {'name': 'MTINet', 'params': '3.5M', 'type': 'Multi-task interaction'},\n",
        "    {'name': 'ENet', 'params': '0.4M', 'type': 'Ultra-lightweight'},\n",
        "    {'name': 'DANet', 'params': '3.2M', 'type': 'Dual attention'}\n",
        "]\n",
        "\n",
        "print(\"Models to train:\")\n",
        "print(\"=\"*70)\n",
        "for i, model_info in enumerate(models_info, 1):\n",
        "    print(f\"{i}. {model_info['name']:<15} | {model_info['params']:<8} | {model_info['type']}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verify All Models (Forward Pass Test)\n",
        "\n",
        "Testing each model to ensure they work correctly before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing on device: cuda\n",
            "\n",
            "======================================================================\n",
            "MODEL VERIFICATION TEST\n",
            "======================================================================\n",
            "Model           Params       Forward    Output Shapes\n",
            "----------------------------------------------------------------------\n",
            "BiSeNetV2       2.77M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "CMX             4.41M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "DDRNetSlim      3.39M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "RTFNet          35.01M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "ESPNetV2        2.22M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "MTINet          1.80M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "ENet            0.26M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "DANet           1.43M       PASS       cls:[2, 3], seg:[2, 3, 480, 640]\n",
            "======================================================================\n",
            "All models passed verification! Ready to train.\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Testing on device: {device}\\n\")\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'BiSeNetV2': BiSeNetV2,\n",
        "    'CMX': CMX,\n",
        "    'DDRNetSlim': DDRNetSlim,\n",
        "    'RTFNet': RTFNet,\n",
        "    'ESPNetV2': ESPNetV2,\n",
        "    'MTINet': MTINet,\n",
        "    'ENet': ENet,\n",
        "    'DANet': DANet\n",
        "}\n",
        "\n",
        "dummy_co2 = torch.randn(2, 1, 480, 640).to(device)\n",
        "dummy_ch4 = torch.randn(2, 1, 480, 640).to(device)\n",
        "dummy_mask = torch.ones(2, 2).to(device)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL VERIFICATION TEST\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Model':<15} {'Params':<12} {'Forward':<10} {'Output Shapes'}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "all_passed = True\n",
        "for name, ModelClass in MODEL_CLASSES.items():\n",
        "    try:\n",
        "        model = ModelClass(num_classes=3, num_seg_classes=3).to(device)\n",
        "        model.eval()\n",
        "        \n",
        "        num_params = model.get_num_parameters()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(dummy_co2, dummy_ch4, dummy_mask)\n",
        "        \n",
        "        cls_shape = outputs['cls_logits'].shape\n",
        "        seg_shape = outputs['co2_seg_logits'].shape\n",
        "        \n",
        "        status = \"PASS\"\n",
        "        shapes = f\"cls:{list(cls_shape)}, seg:{list(seg_shape)}\"\n",
        "        print(f\"{name:<15} {num_params/1e6:.2f}M{'':<6} {status:<10} {shapes}\")\n",
        "        \n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    except Exception as e:\n",
        "        status = \"FAIL\"\n",
        "        all_passed = False\n",
        "        print(f\"{name:<15} {'--':<12} {status:<10} Error: {str(e)[:40]}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "if all_passed:\n",
        "    print(\"All models passed verification! Ready to train.\")\n",
        "else:\n",
        "    print(\"Some models failed. Please fix issues before training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Check Data Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All paired annotation files found\n"
          ]
        }
      ],
      "source": [
        "required_files = [\n",
        "    '../data/paired_train_annotations.csv',\n",
        "    '../data/paired_val_annotations.csv',\n",
        "    '../data/paired_test_annotations.csv'\n",
        "]\n",
        "\n",
        "all_exist = all(os.path.exists(f) for f in required_files)\n",
        "\n",
        "if all_exist:\n",
        "    print(\"All paired annotation files found\")\n",
        "else:\n",
        "    print(\"Paired annotation files not found. Run data/pairing.py first\")\n",
        "    print(\"\\nRun this command in terminal:\")\n",
        "    print(\"  cd data && python pairing.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Start Training All Models\n",
        "\n",
        "This will train all 8 comparison models sequentially.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory: /home/siu856569517/Taminul/Acidosis/FUME\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siu856569517/.conda/envs/fume_env/lib/python3.9/site-packages/wandb/sdk/launch/builder/build.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BATCH TRAINING: COMPARISON MODELS\n",
            "======================================================================\n",
            "Config: configs/fast_comparison_config.yaml\n",
            "Models: BiSeNetV2, CMX, DDRNetSlim, RTFNet, ESPNetV2, MTINet, ENet, DANet\n",
            "Total models: 8\n",
            "======================================================================\n",
            "\n",
            "\n",
            "######################################################################\n",
            "# Training Model 1/8: BiSeNetV2\n",
            "######################################################################\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ðŸš€ Training BiSeNetV2\n",
            "======================================================================\n",
            "Device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siu856569517/.conda/envs/fume_env/lib/python3.9/site-packages/wandb/sdk/launch/builder/build.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaminul\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.23.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/siu856569517/Taminul/Acidosis/FUME/wandb/run-20251202_032225-gy9q54q4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/taminul/FUME-Comparison/runs/gy9q54q4' target=\"_blank\">BiSeNetV2-Fast</a></strong> to <a href='https://wandb.ai/taminul/FUME-Comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/taminul/FUME-Comparison' target=\"_blank\">https://wandb.ai/taminul/FUME-Comparison</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/taminul/FUME-Comparison/runs/gy9q54q4' target=\"_blank\">https://wandb.ai/taminul/FUME-Comparison/runs/gy9q54q4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:data.dataset:Loaded 4383 paired samples\n",
            "INFO:data.dataset:  Fully paired: 1893\n",
            "INFO:data.dataset:  Modality dropout: 0.1\n",
            "INFO:data.dataset:  Class distribution: {'Acidotic': 2734, 'Healthy': 1488, 'Transitional': 161}\n",
            "INFO:data.dataset:Loaded 939 paired samples\n",
            "INFO:data.dataset:  Fully paired: 406\n",
            "INFO:data.dataset:  Modality dropout: 0.0\n",
            "INFO:data.dataset:  Class distribution: {'Acidotic': 586, 'Healthy': 318, 'Transitional': 35}\n",
            "/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler() if self.config['training']['use_amp'] else None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… W&B initialized: FUME-Comparison/BiSeNetV2-Fast\n",
            "   Run ID: gy9q54q4\n",
            "   View at: https://wandb.ai/taminul/FUME-Comparison/runs/gy9q54q4\n",
            "âœ… Data: 4383 train, 939 val\n",
            "âœ… Model: 2,774,857 parameters (2.77M)\n",
            "\n",
            "ðŸš€ Starting Fast Training (15 epochs)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:46<00:00,  1.64it/s, loss=0.6807]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/15\n",
            "  Train Loss: 0.9643 | Val Loss: 0.6435\n",
            "  Balanced Acc: 0.8636 | mIoU: 0.3127\n",
            "  Best Balanced Acc: 0.8636\n",
            "  Time: 2.99 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 2/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:44<00:00,  1.67it/s, loss=1.0139]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/15\n",
            "  Train Loss: 0.7267 | Val Loss: 0.6424\n",
            "  Balanced Acc: 0.8891 | mIoU: 0.4446\n",
            "  Best Balanced Acc: 0.8891\n",
            "  Time: 2.95 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 3/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:46<00:00,  1.65it/s, loss=0.5266]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/15\n",
            "  Train Loss: 0.5826 | Val Loss: 0.4563\n",
            "  Balanced Acc: 0.9426 | mIoU: 0.4317\n",
            "  Best Balanced Acc: 0.9426\n",
            "  Time: 2.97 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 4/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:52<00:00,  1.58it/s, loss=0.3498]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/15\n",
            "  Train Loss: 0.4746 | Val Loss: 0.4684\n",
            "  Balanced Acc: 0.9103 | mIoU: 0.4671\n",
            "  Best Balanced Acc: 0.9426\n",
            "  Time: 3.08 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 5/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:45<00:00,  1.66it/s, loss=0.3920]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/15\n",
            "  Train Loss: 0.4321 | Val Loss: 0.3592\n",
            "  Balanced Acc: 0.9449 | mIoU: 0.5025\n",
            "  Best Balanced Acc: 0.9449\n",
            "  Time: 2.95 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 6/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:49<00:00,  1.62it/s, loss=0.2533]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/15\n",
            "  Train Loss: 0.3563 | Val Loss: 0.3181\n",
            "  Balanced Acc: 0.9679 | mIoU: 0.5203\n",
            "  Best Balanced Acc: 0.9679\n",
            "  Time: 3.02 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 7/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:48<00:00,  1.63it/s, loss=0.2102]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/15\n",
            "  Train Loss: 0.3156 | Val Loss: 0.2825\n",
            "  Balanced Acc: 0.9868 | mIoU: 0.5365\n",
            "  Best Balanced Acc: 0.9868\n",
            "  Time: 3.01 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 8/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:55<00:00,  1.56it/s, loss=0.2114]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/15\n",
            "  Train Loss: 0.2747 | Val Loss: 0.2765\n",
            "  Balanced Acc: 0.9763 | mIoU: 0.6276\n",
            "  Best Balanced Acc: 0.9868\n",
            "  Time: 3.14 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 9/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:41<00:00,  1.70it/s, loss=0.1610]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/15\n",
            "  Train Loss: 0.2491 | Val Loss: 0.2304\n",
            "  Balanced Acc: 0.9766 | mIoU: 0.6979\n",
            "  Best Balanced Acc: 0.9868\n",
            "  Time: 2.90 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 10/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:48<00:00,  1.62it/s, loss=0.2453]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/15\n",
            "  Train Loss: 0.1992 | Val Loss: 0.2235\n",
            "  Balanced Acc: 0.9868 | mIoU: 0.7254\n",
            "  Best Balanced Acc: 0.9868\n",
            "  Time: 3.02 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 11/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:45<00:00,  1.66it/s, loss=0.5699]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11/15\n",
            "  Train Loss: 0.1785 | Val Loss: 0.2107\n",
            "  Balanced Acc: 0.9868 | mIoU: 0.7517\n",
            "  Best Balanced Acc: 0.9868\n",
            "  Time: 2.95 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 12/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:55<00:00,  1.56it/s, loss=0.2887]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12/15\n",
            "  Train Loss: 0.1805 | Val Loss: 0.2223\n",
            "  Balanced Acc: 0.9878 | mIoU: 0.7462\n",
            "  Best Balanced Acc: 0.9878\n",
            "  Time: 3.12 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 13/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:46<00:00,  1.65it/s, loss=0.1216]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13/15\n",
            "  Train Loss: 0.1584 | Val Loss: 0.2231\n",
            "  Balanced Acc: 0.9857 | mIoU: 0.7582\n",
            "  Best Balanced Acc: 0.9878\n",
            "  Time: 2.98 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 14/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:47<00:00,  1.64it/s, loss=0.1179]\n",
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 14/15\n",
            "  Train Loss: 0.1864 | Val Loss: 0.2173\n",
            "  Balanced Acc: 0.9883 | mIoU: 0.7559\n",
            "  Best Balanced Acc: 0.9883\n",
            "  Time: 2.99 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 15/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:47<00:00,  1.64it/s, loss=0.1322]\n",
            "                                                             "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 15/15\n",
            "  Train Loss: 0.1819 | Val Loss: 0.2241\n",
            "  Balanced Acc: 0.9795 | mIoU: 0.7608\n",
            "  Best Balanced Acc: 0.9883\n",
            "  Time: 2.99 min\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "âœ… Training completed in 45.06 minutes!\n",
            "ðŸ“Š Best Balanced Accuracy: 0.9883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
          ]
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">BiSeNetV2-Fast</strong> at: <a href='https://wandb.ai/taminul/FUME-Comparison/runs/gy9q54q4' target=\"_blank\">https://wandb.ai/taminul/FUME-Comparison/runs/gy9q54q4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251202_032225-gy9q54q4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… W&B run finished\n",
            "\n",
            "======================================================================\n",
            "BiSeNetV2 Training Completed\n",
            "Best Balanced Accuracy: 0.9883\n",
            "Training Time: 45.06 minutes\n",
            "======================================================================\n",
            "\n",
            "\n",
            "######################################################################\n",
            "# Training Model 2/8: CMX\n",
            "######################################################################\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ðŸš€ Training CMX\n",
            "======================================================================\n",
            "Device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.23.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/siu856569517/Taminul/Acidosis/FUME/wandb/run-20251202_040735-3qxa4lr8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/taminul/FUME-Comparison/runs/3qxa4lr8' target=\"_blank\">CMX-Fast</a></strong> to <a href='https://wandb.ai/taminul/FUME-Comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/taminul/FUME-Comparison' target=\"_blank\">https://wandb.ai/taminul/FUME-Comparison</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/taminul/FUME-Comparison/runs/3qxa4lr8' target=\"_blank\">https://wandb.ai/taminul/FUME-Comparison/runs/3qxa4lr8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:data.dataset:Loaded 4383 paired samples\n",
            "INFO:data.dataset:  Fully paired: 1893\n",
            "INFO:data.dataset:  Modality dropout: 0.1\n",
            "INFO:data.dataset:  Class distribution: {'Acidotic': 2734, 'Healthy': 1488, 'Transitional': 161}\n",
            "INFO:data.dataset:Loaded 939 paired samples\n",
            "INFO:data.dataset:  Fully paired: 406\n",
            "INFO:data.dataset:  Modality dropout: 0.0\n",
            "INFO:data.dataset:  Class distribution: {'Acidotic': 586, 'Healthy': 318, 'Transitional': 35}\n",
            "/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler() if self.config['training']['use_amp'] else None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… W&B initialized: FUME-Comparison/CMX-Fast\n",
            "   Run ID: 3qxa4lr8\n",
            "   View at: https://wandb.ai/taminul/FUME-Comparison/runs/3qxa4lr8\n",
            "âœ… Data: 4383 train, 939 val\n",
            "âœ… Model: 4,414,673 parameters (4.41M)\n",
            "\n",
            "ðŸš€ Starting Fast Training (15 epochs)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:46<00:00,  1.64it/s, loss=1.3392]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.95 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 2/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:46<00:00,  1.65it/s, loss=1.3265] \n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.94 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 3/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:53<00:00,  1.58it/s, loss=nan]  \n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 3.07 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 4/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:39<00:00,  1.72it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.83 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 5/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:41<00:00,  1.69it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.86 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 6/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:43<00:00,  1.68it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.89 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 7/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:43<00:00,  1.68it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.89 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 8/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [03:00<00:00,  1.52it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 3.18 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 9/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:47<00:00,  1.63it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.96 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 10/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:46<00:00,  1.64it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.95 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 11/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:49<00:00,  1.62it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.99 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 12/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:45<00:00,  1.66it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 2.92 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 13/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [02:59<00:00,  1.53it/s, loss=nan]\n",
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13/15\n",
            "  Train Loss: nan | Val Loss: nan\n",
            "  Balanced Acc: 0.3333 | mIoU: 0.2674\n",
            "  Best Balanced Acc: 0.3333\n",
            "  Time: 3.16 min\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/15:   0%|          | 0/274 [00:00<?, ?it/s]/home/siu856569517/Taminul/Acidosis/FUME/train_all_comparison_models.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):\n",
            "Epoch 14/15:  15%|â–ˆâ–        | 41/274 [00:26<01:26,  2.68it/s, loss=nan]"
          ]
        }
      ],
      "source": [
        "os.chdir('..')\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "from train_all_comparison_models import FastTrainer\n",
        "\n",
        "models_to_train = [\n",
        "    'BiSeNetV2',\n",
        "    'CMX',\n",
        "    'DDRNetSlim',\n",
        "    'RTFNet',\n",
        "    'ESPNetV2',\n",
        "    'MTINet',\n",
        "    'ENet',\n",
        "    'DANet'\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BATCH TRAINING: COMPARISON MODELS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Config: configs/fast_comparison_config.yaml\")\n",
        "print(f\"Models: {', '.join(models_to_train)}\")\n",
        "print(f\"Total models: {len(models_to_train)}\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for i, model_name in enumerate(models_to_train, 1):\n",
        "    print(f\"\\n{'#'*70}\")\n",
        "    print(f\"# Training Model {i}/{len(models_to_train)}: {model_name}\")\n",
        "    print(f\"{'#'*70}\\n\")\n",
        "    \n",
        "    try:\n",
        "        trainer = FastTrainer('configs/fast_comparison_config.yaml', model_name)\n",
        "        result = trainer.train()\n",
        "        results.append(result)\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"{model_name} Training Completed\")\n",
        "        print(f\"Best Balanced Accuracy: {result['best_metric']:.4f}\")\n",
        "        print(f\"Training Time: {result['training_time']/60:.2f} minutes\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nError training {model_name}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        continue\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL MODELS TRAINING COMPLETED\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if results:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING SUMMARY - RANKED BY PERFORMANCE\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    results_sorted = sorted(results, key=lambda x: x['best_metric'], reverse=True)\n",
        "    \n",
        "    print(f\"\\n{'Rank':<6}{'Model':<15}{'Bal. Acc':<12}{'mIoU':<10}{'F1':<10}{'Time (min)'}\")\n",
        "    print(\"-\"*70)\n",
        "    \n",
        "    for i, result in enumerate(results_sorted, 1):\n",
        "        print(f\"{i:<6}{result['model_name']:<15}\"\n",
        "              f\"{result['best_metric']:<12.4f}\"\n",
        "              f\"{result['final_results']['seg']['mean_iou']:<10.4f}\"\n",
        "              f\"{result['final_results']['cls']['macro_f1']:<10.4f}\"\n",
        "              f\"{result['training_time']/60:.2f}\")\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    print(\"\\nDetailed Results:\")\n",
        "    print(\"=\"*70)\n",
        "    for i, result in enumerate(results_sorted, 1):\n",
        "        print(f\"\\n{i}. {result['model_name']}\")\n",
        "        print(f\"   Best Balanced Accuracy: {result['best_metric']:.4f}\")\n",
        "        print(f\"   Mean IoU: {result['final_results']['seg']['mean_iou']:.4f}\")\n",
        "        print(f\"   Mean Dice: {result['final_results']['seg']['mean_dice']:.4f}\")\n",
        "        print(f\"   Macro F1: {result['final_results']['cls']['macro_f1']:.4f}\")\n",
        "        print(f\"   Training Time: {result['training_time']/60:.2f} min\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"All models trained successfully\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"No results available. Training may have failed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if results:\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    results_dir = Path('../results_comparison')\n",
        "    results_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    summary = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'config': {\n",
        "            'epochs': config['training']['num_epochs'],\n",
        "            'batch_size': config['training']['batch_size'],\n",
        "            'learning_rate': config['training']['optimizer']['lr'],\n",
        "        },\n",
        "        'results': results\n",
        "    }\n",
        "    \n",
        "    summary_path = results_dir / 'training_summary.json'\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    \n",
        "    print(f\"Results summary saved to: {summary_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Check Model Checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoints_dir = Path('../checkpoints_comparison')\n",
        "\n",
        "if checkpoints_dir.exists():\n",
        "    print(\"Model Checkpoints:\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for model_name in models_to_train:\n",
        "        model_dir = checkpoints_dir / model_name\n",
        "        if model_dir.exists():\n",
        "            best_ckpt = model_dir / 'best_model.pth'\n",
        "            last_ckpt = model_dir / 'last_model.pth'\n",
        "            \n",
        "            status = \"âœ“\" if best_ckpt.exists() else \"âœ—\"\n",
        "            print(f\"{status} {model_name:<15} - {model_dir}\")\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"No checkpoints directory found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. Training completed\n",
        "2. Evaluate all models on test set\n",
        "3. Compare with FUME-FastSCNN results\n",
        "4. Generate comparison tables and figures\n",
        "5. Analyze performance differences\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fume_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
